{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42420b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Notebook: Entrenamiento y Evaluaci√≥n de Modelos\n",
    "# ================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # üöÄ Pipeline Completo de Entrenamiento y Evaluaci√≥n\n",
    "# \n",
    "# Este notebook ejecuta el pipeline completo:\n",
    "# 1. Carga y preprocesamiento de datos\n",
    "# 2. Ingenier√≠a de caracter√≠sticas\n",
    "# 3. Entrenamiento de 4 modelos (LSTM, GRU, TCN, TFT)\n",
    "# 4. Evaluaci√≥n y comparaci√≥n\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üì¶ Imports\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Agregar path del proyecto\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils import load_config, set_seed, create_directories\n",
    "from src.data_loader import StockDataLoader\n",
    "from src.features import FeatureEngineering\n",
    "from src.train import TrainingPipeline\n",
    "from src.evaluate import evaluate_from_pipeline\n",
    "\n",
    "# Configurar estilo\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Imports completados\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ‚öôÔ∏è Configuraci√≥n\n",
    "\n",
    "# %%\n",
    "# Cargar configuraci√≥n\n",
    "config = load_config('../config.yaml')\n",
    "set_seed(config['training']['random_seed'])\n",
    "create_directories(config)\n",
    "\n",
    "print(\"Configuraci√≥n cargada:\")\n",
    "print(f\"  - Lookback: {config['features']['lookback_window']} d√≠as\")\n",
    "print(f\"  - Horizonte: {config['features']['prediction_horizon']} d√≠a(s)\")\n",
    "print(f\"  - Train hasta: {config['data']['train_end']}\")\n",
    "print(f\"  - Val hasta: {config['data']['val_end']}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üîç Exploraci√≥n R√°pida de Datos\n",
    "\n",
    "# %%\n",
    "# Cargar datos procesados\n",
    "loader = StockDataLoader(config)\n",
    "df = loader.load_full_data()\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"  - Filas: {len(df):,}\")\n",
    "print(f\"  - Tickers: {df['ticker'].nunique()}\")\n",
    "print(f\"  - Rango: {df['Date'].min().date()} ‚Üí {df['Date'].max().date()}\")\n",
    "\n",
    "# Visualizar distribuci√≥n de precios\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['Close'], bins=100, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Precio de Cierre ($)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribuci√≥n de Precios')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "top_tickers = df['ticker'].value_counts().head(10)\n",
    "plt.barh(range(len(top_tickers)), top_tickers.values)\n",
    "plt.yticks(range(len(top_tickers)), top_tickers.index)\n",
    "plt.xlabel('N√∫mero de registros')\n",
    "plt.title('Top 10 Tickers por cantidad de datos')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üèãÔ∏è Entrenamiento de Modelos\n",
    "# \n",
    "# **ADVERTENCIA**: Esto puede tardar varios minutos u horas dependiendo de:\n",
    "# - Tama√±o del dataset\n",
    "# - Hardware disponible (GPU recomendada)\n",
    "# - N√∫mero de epochs\n",
    "\n",
    "# %%\n",
    "# Crear pipeline\n",
    "pipeline = TrainingPipeline('../config.yaml')\n",
    "\n",
    "# Opci√≥n 1: Entrenar todos los modelos\n",
    "models_to_train = ['lstm', 'gru', 'tcn', 'tft']\n",
    "\n",
    "# Opci√≥n 2: Entrenar solo algunos (m√°s r√°pido para pruebas)\n",
    "# models_to_train = ['lstm', 'gru']\n",
    "\n",
    "print(f\"\\nüéØ Modelos a entrenar: {models_to_train}\")\n",
    "print(\"‚è≥ Iniciando entrenamiento (puede tardar)...\\n\")\n",
    "\n",
    "# Ejecutar pipeline completo\n",
    "trained_models = pipeline.run(models=models_to_train)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìä Visualizaci√≥n de Historiales de Entrenamiento\n",
    "\n",
    "# %%\n",
    "import json\n",
    "\n",
    "fig, axes = plt.subplots(len(trained_models), 2, figsize=(14, 4*len(trained_models)))\n",
    "\n",
    "if len(trained_models) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, (model_name, model_data) in enumerate(trained_models.items()):\n",
    "    history = model_data['history'].history\n",
    "    \n",
    "    # Loss\n",
    "    ax1 = axes[idx, 0] if len(trained_models) > 1 else axes[0]\n",
    "    ax1.plot(history['loss'], label='Train Loss', linewidth=2)\n",
    "    ax1.plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    ax1.set_title(f'{model_name.upper()} - Loss', fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # MAE\n",
    "    ax2 = axes[idx, 1] if len(trained_models) > 1 else axes[1]\n",
    "    ax2.plot(history['mae'], label='Train MAE', linewidth=2)\n",
    "    ax2.plot(history['val_mae'], label='Val MAE', linewidth=2)\n",
    "    ax2.set_title(f'{model_name.upper()} - MAE', fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Historiales guardados en results/plots/training_history.png\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üß™ Evaluaci√≥n en Test Set\n",
    "# \n",
    "# Ahora evaluaremos los modelos en datos nunca vistos (test set)\n",
    "\n",
    "# %%\n",
    "# Preparar datos de test (reutilizando el pipeline)\n",
    "print(\"‚è≥ Preparando datos de test...\")\n",
    "\n",
    "# Cargar y preparar datos\n",
    "train_df, val_df, test_df = pipeline.load_and_prepare_data()\n",
    "train_df, val_df, test_df = pipeline.engineer_features(train_df, val_df, test_df)\n",
    "\n",
    "results = pipeline.create_sequences(train_df, val_df, test_df)\n",
    "(X_train, y_train, _, _, X_val, y_val, _, _, \n",
    " X_test, y_test, test_tickers, test_dates, feature_cols) = results\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = pipeline.normalize_data(\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test\n",
    ")\n",
    "\n",
    "print(f\"‚úì Test set preparado: {X_test.shape}\")\n",
    "\n",
    "# Evaluar todos los modelos\n",
    "print(\"\\n‚è≥ Evaluando modelos en test set...\\n\")\n",
    "eval_results, df_results = evaluate_from_pipeline(\n",
    "    X_test, y_test, \n",
    "    models=models_to_train\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìà An√°lisis de Resultados\n",
    "\n",
    "# %%\n",
    "# Mostrar tabla de resultados\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RANKING DE MODELOS (por RMSE)\")\n",
    "print(\"=\"*70)\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model = df_results.iloc[0]['Model']\n",
    "best_rmse = df_results.iloc[0]['RMSE']\n",
    "best_r2 = df_results.iloc[0]['R2']\n",
    "\n",
    "print(f\"üèÜ MEJOR MODELO: {best_model}\")\n",
    "print(f\"   RMSE: ${best_rmse:.4f}\")\n",
    "print(f\"   R¬≤: {best_r2:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üéØ An√°lisis de Errores\n",
    "\n",
    "# %%\n",
    "# Calcular errores para el mejor modelo\n",
    "best_result = [r for r in eval_results if r['model_name'] == best_model.lower()][0]\n",
    "errors = best_result['y_pred'] - best_result['y_true']\n",
    "percentage_errors = (errors / best_result['y_true']) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Distribuci√≥n de errores\n",
    "axes[0].hist(errors, bins=100, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2, label='Error = 0')\n",
    "axes[0].set_xlabel('Error ($)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_title(f'{best_model} - Distribuci√≥n de Errores')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Errores porcentuales\n",
    "axes[1].hist(percentage_errors, bins=100, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Error (%)')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].set_title('Distribuci√≥n de Errores Porcentuales')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Errores vs valor real\n",
    "axes[2].scatter(best_result['y_true'], errors, alpha=0.3, s=10)\n",
    "axes[2].axhline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[2].set_xlabel('Valor Real ($)')\n",
    "axes[2].set_ylabel('Error ($)')\n",
    "axes[2].set_title('Errores vs Valores Reales')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de errores\n",
    "print(\"\\nEstad√≠sticas de Errores:\")\n",
    "print(f\"  Media: ${errors.mean():.4f}\")\n",
    "print(f\"  Mediana: ${np.median(errors):.4f}\")\n",
    "print(f\"  Std: ${errors.std():.4f}\")\n",
    "print(f\"  MAPE: {percentage_errors.abs().mean():.2f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üíæ Guardar Resultados Finales\n",
    "\n",
    "# %%\n",
    "# Crear resumen final\n",
    "summary = {\n",
    "    'best_model': best_model,\n",
    "    'metrics': df_results.to_dict('records'),\n",
    "    'dataset_info': {\n",
    "        'train_samples': int(len(X_train)),\n",
    "        'val_samples': int(len(X_val)),\n",
    "        'test_samples': int(len(X_test)),\n",
    "        'features': feature_cols,\n",
    "        'tickers': int(df['ticker'].nunique())\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../results/final_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"‚úì Resumen guardado en results/final_summary.json\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üéâ Conclusi√≥n\n",
    "# \n",
    "# El pipeline completo ha sido ejecutado exitosamente. Los resultados incluyen:\n",
    "# - **Modelos entrenados**: Guardados en `results/models/`\n",
    "# - **Gr√°ficos**: Guardados en `results/plots/`\n",
    "# - **Tablas**: Guardadas en `results/tables/`\n",
    "# - **Resumen**: `results/final_summary.json`\n",
    "# \n",
    "# ### Pr√≥ximos pasos:\n",
    "# 1. Analizar resultados en profundidad\n",
    "# 2. Ajustar hiperpar√°metros si es necesario\n",
    "# 3. Probar con diferentes ventanas temporales\n",
    "# 4. Implementar predicciones en producci√≥n\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ PIPELINE COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
