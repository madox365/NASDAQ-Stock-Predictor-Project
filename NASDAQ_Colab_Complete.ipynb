{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4efd8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# NASDAQ Stock Prediction - Google Colab\n",
    "# =======================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # üöÄ Predicci√≥n de Acciones NASDAQ en Google Colab\n",
    "# \n",
    "# Este notebook ejecuta TODO el pipeline en Colab con GPU gratis\n",
    "# \n",
    "# **Duraci√≥n estimada:** 2-3 horas\n",
    "\n",
    "# %% [markdown]\n",
    "# ## ‚öôÔ∏è PASO 1: Configurar GPU\n",
    "\n",
    "# %%\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Verificar memoria disponible\n",
    "!cat /proc/meminfo | grep MemTotal\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìÇ PASO 2: Montar Google Drive y descomprimir proyecto\n",
    "\n",
    "# %%\n",
    "from google.colab import drive\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Montar Drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Verificar que el ZIP existe\n",
    "zip_path = '/content/drive/MyDrive/NASDAQ_Project/proyecto_nasdaq.zip'\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    print(f\"‚úÖ ZIP encontrado: {zip_path}\")\n",
    "    \n",
    "    # Descomprimir en /content/ (m√°s r√°pido que Drive)\n",
    "    print(\"üì¶ Descomprimiendo proyecto...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content/')\n",
    "    \n",
    "    print(\"‚úÖ Proyecto descomprimido\")\n",
    "else:\n",
    "    print(f\"‚ùå ERROR: No se encontr√≥ el archivo en {zip_path}\")\n",
    "    print(\"\\nüîß Soluci√≥n:\")\n",
    "    print(\"1. Sube 'proyecto_nasdaq.zip' a tu Google Drive\")\n",
    "    print(\"2. Col√≥calo en: MyDrive/NASDAQ_Project/\")\n",
    "    print(\"3. O cambia la ruta 'zip_path' arriba\")\n",
    "\n",
    "# %%\n",
    "# Ir a la carpeta del proyecto\n",
    "%cd /content/NASDAQ_Stock_Prediction_Project\n",
    "\n",
    "# Verificar estructura\n",
    "print(\"\\nüìÅ Estructura del proyecto:\")\n",
    "!ls -la\n",
    "\n",
    "# Verificar que stocks_full.csv existe\n",
    "if os.path.exists('data/processed/stocks_full.csv'):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/processed/stocks_full.csv', nrows=5)\n",
    "    print(\"\\n‚úÖ stocks_full.csv encontrado\")\n",
    "    print(f\"   Columnas: {df.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: data/processed/stocks_full.csv NO existe\")\n",
    "    print(\"   Debes incluirlo en el ZIP\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üì¶ PASO 3: Instalar dependencias\n",
    "\n",
    "# %%\n",
    "# Instalar todas las dependencias\n",
    "!pip install -q pandas numpy scikit-learn matplotlib seaborn plotly pyyaml tqdm ta\n",
    "\n",
    "print(\"‚úÖ Dependencias instaladas\")\n",
    "\n",
    "# Verificar versiones clave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(f\"\\nVersiones:\")\n",
    "print(f\"  Pandas: {pd.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "print(f\"  TensorFlow: {tf.__version__}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üîß PASO 4: Ajustar configuraci√≥n para Colab\n",
    "\n",
    "# %%\n",
    "import yaml\n",
    "\n",
    "# Leer config\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Configuraci√≥n actual:\")\n",
    "print(f\"  Lookback: {config['features']['lookback_window']}\")\n",
    "print(f\"  Epochs LSTM: {config['models']['lstm']['epochs']}\")\n",
    "print(f\"  Batch size: {config['models']['lstm']['batch_size']}\")\n",
    "\n",
    "# AJUSTAR PARA COLAB (opcional - para que sea m√°s r√°pido)\n",
    "# Descomenta si quieres prueba r√°pida:\n",
    "\n",
    "# config['features']['lookback_window'] = 30  # Reducir RAM\n",
    "# config['models']['lstm']['epochs'] = 20     # Menos epochs\n",
    "# config['models']['lstm']['batch_size'] = 64 # Batch m√°s grande\n",
    "# \n",
    "# with open('config.yaml', 'w') as f:\n",
    "#     yaml.dump(config, f)\n",
    "# \n",
    "# print(\"\\n‚úÖ Config ajustado para Colab\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìä PASO 5: Exploraci√≥n r√°pida de datos\n",
    "\n",
    "# %%\n",
    "from src.utils import load_config, create_directories\n",
    "from src.data_loader import StockDataLoader\n",
    "\n",
    "config = load_config('config.yaml')\n",
    "create_directories(config)\n",
    "\n",
    "loader = StockDataLoader(config)\n",
    "df = loader.load_full_data()\n",
    "\n",
    "print(f\"\\nüìä Dataset filtrado:\")\n",
    "print(f\"  Filas: {len(df):,}\")\n",
    "print(f\"  Tickers: {df['ticker'].nunique()}\")\n",
    "print(f\"  Rango: {df['Date'].min().date()} ‚Üí {df['Date'].max().date()}\")\n",
    "print(f\"  RAM usada: {df.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "\n",
    "# Top 10 tickers\n",
    "print(f\"\\nüîù Top 10 tickers por registros:\")\n",
    "print(df['ticker'].value_counts().head(10))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üóÇÔ∏è PASO 6: Generar Splits (Train/Val/Test)\n",
    "\n",
    "# %%\n",
    "import os\n",
    "\n",
    "# Verificar si ya existen\n",
    "if os.path.exists('data/processed/train.csv'):\n",
    "    print(\"‚úÖ Splits ya existen, saltando generaci√≥n...\")\n",
    "else:\n",
    "    print(\"üìä Generando splits...\")\n",
    "    train, val, test = loader.split_data(df)\n",
    "    loader.save_splits(train, val, test)\n",
    "    print(\"‚úÖ Splits generados\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üèãÔ∏è PASO 7: ENTRENAR MODELOS\n",
    "# \n",
    "# **‚ö†Ô∏è IMPORTANTE:** \n",
    "# - Esto tardar√° 1-3 horas dependiendo del modelo\n",
    "# - Colab Free puede desconectarse despu√©s de ~12 horas\n",
    "# - Recomiendo entrenar de a un modelo por sesi√≥n\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Opci√≥n A: Entrenar SOLO LSTM (30-60 min)\n",
    "\n",
    "# %%\n",
    "from src.train import TrainingPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üèãÔ∏è Entrenando LSTM...\")\n",
    "print(\"‚è±Ô∏è Tiempo estimado: 30-60 minutos en GPU\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "pipeline = TrainingPipeline('config.yaml')\n",
    "\n",
    "try:\n",
    "    trained_models = pipeline.run(models=['lstm'])\n",
    "    print(\"\\n‚úÖ LSTM entrenado exitosamente\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR: {e}\")\n",
    "    print(\"\\nüîß Si el error es de memoria:\")\n",
    "    print(\"   1. Reduce lookback_window a 30 en config.yaml\")\n",
    "    print(\"   2. O filtra menos tickers (selected_tickers)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Opci√≥n B: Entrenar LSTM + GRU (1-2 horas)\n",
    "\n",
    "# %%\n",
    "# ‚ö†Ô∏è Descomenta para entrenar 2 modelos\n",
    "# pipeline = TrainingPipeline('config.yaml')\n",
    "# trained_models = pipeline.run(models=['lstm', 'gru'])\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Opci√≥n C: Entrenar TODOS (2-4 horas)\n",
    "\n",
    "# %%\n",
    "# ‚ö†Ô∏è Solo para Colab Pro o si tienes tiempo\n",
    "# pipeline = TrainingPipeline('config.yaml')\n",
    "# trained_models = pipeline.run(models=['lstm', 'gru', 'tcn', 'tft'])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üìä PASO 8: Visualizar Historial de Entrenamiento\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Cargar historial del modelo entrenado\n",
    "with open('results/models/lstm_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history['loss'], label='Train Loss', linewidth=2)\n",
    "ax1.plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "ax1.set_title('LSTM - Loss durante entrenamiento', fontweight='bold', fontsize=14)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss (MSE)')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "ax2.plot(history['mae'], label='Train MAE', linewidth=2)\n",
    "ax2.plot(history['val_mae'], label='Val MAE', linewidth=2)\n",
    "ax2.set_title('LSTM - MAE durante entrenamiento', fontweight='bold', fontsize=14)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/plots/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Mejor val_loss: {min(history['val_loss']):.6f}\")\n",
    "print(f\"   Alcanzado en epoch: {history['val_loss'].index(min(history['val_loss'])) + 1}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üß™ PASO 9: Evaluar en Test Set\n",
    "\n",
    "# %%\n",
    "from src.evaluate import ModelEvaluator\n",
    "import pickle\n",
    "\n",
    "print(\"üìä Preparando evaluaci√≥n...\")\n",
    "\n",
    "# Cargar scalers\n",
    "with open('results/models/feature_scaler.pkl', 'rb') as f:\n",
    "    feature_scaler = pickle.load(f)\n",
    "with open('results/models/target_scaler.pkl', 'rb') as f:\n",
    "    target_scaler = pickle.load(f)\n",
    "\n",
    "# Cargar metadata\n",
    "with open('results/models/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Metadata cargado\")\n",
    "print(f\"   Features: {len(metadata['feature_cols'])}\")\n",
    "print(f\"   Test samples: {metadata['test_samples']:,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# **‚ö†Ô∏è NOTA:** Para evaluaci√≥n completa, necesitas ejecutar el pipeline\n",
    "# completo que genera X_test, y_test. Ver notebook 03_train_and_evaluate.ipynb\n",
    "\n",
    "# %%\n",
    "# Evaluaci√≥n simplificada - cargar modelo y verificar\n",
    "from src.models.lstm import LSTMModel\n",
    "\n",
    "input_shape = tuple(metadata['input_shape'])\n",
    "lstm_model = LSTMModel(config, input_shape)\n",
    "lstm_model.load_weights('results/models/lstm_best.h5')\n",
    "\n",
    "print(\"‚úÖ Modelo LSTM cargado correctamente\")\n",
    "lstm_model.summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üíæ PASO 10: Descargar Resultados\n",
    "\n",
    "# %%\n",
    "# Comprimir resultados\n",
    "!zip -r results_nasdaq.zip results/\n",
    "\n",
    "print(\"\\nüì¶ Resultados comprimidos en: results_nasdaq.zip\")\n",
    "print(\"   Tama√±o:\")\n",
    "!du -h results_nasdaq.zip\n",
    "\n",
    "# Descargar\n",
    "from google.colab import files\n",
    "files.download('results_nasdaq.zip')\n",
    "\n",
    "print(\"\\n‚úÖ ¬°Descarga iniciada!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## üéâ ¬°COMPLETADO!\n",
    "# \n",
    "# ### üìã Resumen de archivos generados:\n",
    "# - **Modelos**: `results/models/*.h5`\n",
    "# - **Gr√°ficos**: `results/plots/*.png`\n",
    "# - **Tablas**: `results/tables/*.csv`\n",
    "# - **Scalers**: `results/models/*_scaler.pkl`\n",
    "# \n",
    "# ### üîÑ Pr√≥ximos pasos:\n",
    "# 1. Descarga `results_nasdaq.zip`\n",
    "# 2. Descompr√≠melo en tu proyecto local\n",
    "# 3. Analiza resultados en tu computadora\n",
    "# 4. Repite con otros modelos (GRU, TCN, TFT)\n",
    "# \n",
    "# ### üí° Tips:\n",
    "# - Guarda este notebook en tu Drive\n",
    "# - Los modelos entrenados se pueden reutilizar\n",
    "# - Para entrenar otros modelos, solo cambia `models=['gru']`\n",
    "\n",
    "# %% [markdown]\n",
    "# ---\n",
    "# **Creado para el proyecto NASDAQ Stock Prediction**  \n",
    "# Si hay errores, revisa la secci√≥n de configuraci√≥n y ajusta seg√∫n tu RAM/GPU"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
